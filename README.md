# MasterThesisProject

Applied Computer Science fiield - Software, AI and embedded systems.

"Embedded aplication device, determining piano sound color using AI."

AI recognizes 3 sound colors:
 - soft
 - bright
 - generic

Needed libraries for train and data sorting & split: 

pip install pyroomacoustics tensorflow librosa numpy keras matplotlib audiomentations scikit-learn pandas tensorflow-probability tf-keras  joblib 


Repository provides code for preparing and training model inf folder AI (my tflite models included) and RasPi folder, for code and operations needed to run application on Easpberry Pi.

I work on data prepared by myself. 3 Piano sound classes for A4 key.
 
Repository contains two directories. First contains code for ML preparation, second one describes how to set enviroment and application, including model deployment, on Raspberry Pi (in my case model 4B, Bookworm OS). 

ML determines sound color based on analysis of MEL-Spectrograms. Data is generated by creating MEL-Spectrogram graphs of ~~augmented (possible by using audiomentation library)~~ acoustic and synthetic keyboard .wav files.

Used neural net: CNN

Model generated from: https://teachablemachine.withgoogle.com/

Data is processed by image recognition.

For Raspberry application, we need to have python installed. Needed libraries:

sudo apt update
sudo apt install libsdl2-dev libsdl2-ttf-dev libsdl2-image-dev libsdl2-mixer-dev

sudo apt-get install ffmpeg

sudo apt install portaudio19-dev

pip3 install tensorflow soundfile numpy librosa sounddevice matplotlib pillow kivy ffmpeg-python tflite-runtime

ffpyplayer and kivy: https://gist.github.com/P1kachu/65dceb8252f277d68229ad6e8df99c69

GStream is needed.
 
Graphic interface will be written using Kivy:  https://kivy.org/doc/stable/installation/installation-rpi.html , https://kivy.org/doc/stable/gettingstarted/installation.html#installation-canonical 

Animations were made in blender.



