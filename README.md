# MasterThesisProject

It is software and embedded field.

"Embedded aplication device, determining piano sound color using AI."

AI recognizes 3 sound colors:
 - dark
 - bright
 - generic

Needed libraries for train and data sorting & split: 

pip install pyroomacoustics tensorflow librosa numpy keras matplotlib audiomentations scikit-learn pandas tensorflow-probability tf-keras  joblib 


Repository provides code for preparing and training model inf folder AI (my tflite models included) and RasPi folder, for code and operations needed to run application on Easpberry Pi.

I work on data prepared by myself. 3 Piano sound classes for A4 key.
 
Repository contains two directories. First contains code for ML preparation, second one describes how to set enviroment and application, including model deployment, on Raspberry Pi (in my case model 4B, Bookworm OS). 

ML determines sound color based on analysis of MEL-Spectrograms. Data is generated by creating MEL-Spectrogram graphs of ~~augmented (possible by using audiomentation library)~~ acoustic and synthetic keyboard .wav files.

Used neural net: CNN

Model generated from: https://teachablemachine.withgoogle.com/

Data is processed by image recognition.

For Raspberry application, we need to have python installed. Needed libraries:

pip3 install tensorflow librosa sounddevice matplotlib pillow

Graphic interface will be written using Kivy:  https://kivy.org/doc/stable/installation/installation-rpi.html , https://kivy.org/doc/stable/gettingstarted/installation.html#installation-canonical 

Animations will be made with Synfig.



